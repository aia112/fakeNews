{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Title  \\\n",
      "0         How Trump's presidency has played for Russia   \n",
      "1    Tokyo 2020 Olympics: Japanese PM Abe insists G...   \n",
      "2       Coronavirus is Boris Johnson's worst nightmare   \n",
      "3    She heard a woman yelling at the grocery store...   \n",
      "4    Here's what could really sink the global econo...   \n",
      "..                                                 ...   \n",
      "897  Trump Ends North Korean Talks Early After Kim ...   \n",
      "898  Doctors Warn Drinking A Shot Every Time Trump ...   \n",
      "899  Trump Looking Forward To Knighthood From The Q...   \n",
      "900  Nation Wonders How Much More Fucking Evidence ...   \n",
      "901  President Trump Alleges He Was Sexually Assaul...   \n",
      "\n",
      "                                                Tokens  \\\n",
      "0                  [trump, presidency, played, russia]   \n",
      "1    [tokyo, olympics, japanese, pm, abe, insists, ...   \n",
      "2        [coronavirus, boris, johnson, bad, nightmare]   \n",
      "3    [heard, woman, yell, grocery, store, next, mov...   \n",
      "4    [could, really, sink, global, economy, trillio...   \n",
      "..                                                 ...   \n",
      "897  [trump, end, north, korean, talk, early, kim, ...   \n",
      "898  [doctor, warn, drinking, shot, everi, time, tr...   \n",
      "899          [trump, look, forward, knighthood, queen]   \n",
      "900  [nation, wonder, fuck, evidence, mueller, need...   \n",
      "901  [president, trump, alleges, sexually, assault,...   \n",
      "\n",
      "                                           TitleString  \n",
      "0                       trump presidency played russia  \n",
      "1    tokyo olympics japanese pm abe insists game go...  \n",
      "2              coronavirus boris johnson bad nightmare  \n",
      "3    heard woman yell grocery store next move drew ...  \n",
      "4    could really sink global economy trillion risk...  \n",
      "..                                                 ...  \n",
      "897  trump end north korean talk early kim suggests...  \n",
      "898  doctor warn drinking shot everi time trump lie...  \n",
      "899                trump look forward knighthood queen  \n",
      "900   nation wonder fuck evidence mueller need exactly  \n",
      "901  president trump alleges sexually assault hilla...  \n",
      "\n",
      "[902 rows x 3 columns]\n",
      "                                                  Text  \\\n",
      "0    But you don't need James Bond to recognize the...   \n",
      "1    (CNN) Japanese prime minister Shinzo Abe insis...   \n",
      "2    London (CNN) The outbreak of the novel coronav...   \n",
      "3    Chat with us in Facebook Messenger. Find out w...   \n",
      "4    London (CNN Business) Companies have spent the...   \n",
      "..                                                 ...   \n",
      "897  HANOI, VIETNAM—New details have emerged sugges...   \n",
      "898  A viral drinking game that involves consuming ...   \n",
      "899  LONDON, UK—Donald Trump has tweeted his excite...   \n",
      "900  After over a year of accumulating what many as...   \n",
      "901  FUSSA, JAPAN—The President of the United State...   \n",
      "\n",
      "                                                Tokens  \\\n",
      "0    [need, james, bond, recogn, fact, modern, amer...   \n",
      "1    [cnn, japanese, prime, minister, shinzo, abe, ...   \n",
      "2    [london, cnn, outbreak, novel, coronavirus, ca...   \n",
      "3    [chat, us, facebook, messenger, find, happen, ...   \n",
      "4    [london, cnn, business, company, spent, year, ...   \n",
      "..                                                 ...   \n",
      "897  [hanoi, detail, emerg, suggest, president, tru...   \n",
      "898  [viral, drinking, game, involves, consum, shot...   \n",
      "899  [london, trump, tweet, excitement, becom, firs...   \n",
      "900  [accumul, many, assum, damn, evidence, ever, s...   \n",
      "901  [fussa, president, united, state, begun, tour,...   \n",
      "\n",
      "                                            TextString  \n",
      "0    need james bond recogn fact modern american pr...  \n",
      "1    cnn japanese prime minister shinzo abe insist ...  \n",
      "2    london cnn outbreak novel coronavirus caus pol...  \n",
      "3    chat us facebook messenger find happen world u...  \n",
      "4    london cnn business company spent year sinc gl...  \n",
      "..                                                 ...  \n",
      "897  hanoi detail emerg suggest president trump wal...  \n",
      "898  viral drinking game involves consum shot everi...  \n",
      "899  london trump tweet excitement becom first amer...  \n",
      "900  accumul many assum damn evidence ever sit pres...  \n",
      "901  fussa president united state begun tour asia m...  \n",
      "\n",
      "[902 rows x 3 columns]\n",
      "0       True\n",
      "1       True\n",
      "2       True\n",
      "3       True\n",
      "4       True\n",
      "       ...  \n",
      "897    False\n",
      "898    False\n",
      "899    False\n",
      "900    False\n",
      "901    False\n",
      "Name: Label, Length: 902, dtype: bool\n",
      "0                       CNN\n",
      "1                       CNN\n",
      "2                       CNN\n",
      "3                       CNN\n",
      "4                       CNN\n",
      "               ...         \n",
      "897    burrardstreetjournal\n",
      "898    burrardstreetjournal\n",
      "899    burrardstreetjournal\n",
      "900    burrardstreetjournal\n",
      "901    burrardstreetjournal\n",
      "Name: Company, Length: 902, dtype: object\n"
     ]
    }
   ],
   "source": [
    "### Load Data ###\n",
    "with open(\"pickles/titles\", \"rb\") as file:\n",
    "    titles = pickle.load(file)\n",
    "with open(\"pickles/texts\", \"rb\") as file:\n",
    "    texts = pickle.load(file)\n",
    "df = pd.read_csv(\"dataset/dataset.csv\")\n",
    "labels = df[\"Label\"]\n",
    "source = df[\"Company\"]\n",
    "print(titles)\n",
    "print(texts)\n",
    "print(labels)\n",
    "print(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         trump presidency played russia\n",
       "1      tokyo olympics japanese pm abe insists game go...\n",
       "2                coronavirus boris johnson bad nightmare\n",
       "3      heard woman yell grocery store next move drew ...\n",
       "4      could really sink global economy trillion risk...\n",
       "                             ...                        \n",
       "897    trump end north korean talk early kim suggests...\n",
       "898    doctor warn drinking shot everi time trump lie...\n",
       "899                  trump look forward knighthood queen\n",
       "900     nation wonder fuck evidence mueller need exactly\n",
       "901    president trump alleges sexually assault hilla...\n",
       "Name: TitleString, Length: 902, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TitleString = titles[\"TitleString\"]\n",
    "TitleString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titleVector = TfidfVectorizer()\n",
    "titleVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleVectorArray = titleVector.fit_transform(TitleString).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      need james bond recogn fact modern american pr...\n",
       "1      cnn japanese prime minister shinzo abe insist ...\n",
       "2      london cnn outbreak novel coronavirus caus pol...\n",
       "3      chat us facebook messenger find happen world u...\n",
       "4      london cnn business company spent year sinc gl...\n",
       "                             ...                        \n",
       "897    hanoi detail emerg suggest president trump wal...\n",
       "898    viral drinking game involves consum shot everi...\n",
       "899    london trump tweet excitement becom first amer...\n",
       "900    accumul many assum damn evidence ever sit pres...\n",
       "901    fussa president united state begun tour asia m...\n",
       "Name: TextString, Length: 902, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextString = texts[\"TextString\"]\n",
    "TextString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "textVector = TfidfVectorizer()\n",
    "textVectorArray = textVector.fit_transform(TextString).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "0       True\n",
      "1       True\n",
      "2       True\n",
      "3       True\n",
      "4       True\n",
      "       ...  \n",
      "897    False\n",
      "898    False\n",
      "899    False\n",
      "900    False\n",
      "901    False\n",
      "Name: Label, Length: 902, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(textVectorArray)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Learning on Just Title ####\n",
    "### SPLIT DATASET ###\n",
    "title_train,title_test,label_train,label_test = train_test_split(titleVectorArray, labels, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fraction of true Labels in training Set\n",
    "## print(list(label_train).count(True)/len(list(label_train)))\n",
    "## Fraction of true Labels in Test Set\n",
    "## print(list(label_test).count(True)/len(list(label_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(title_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(title_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy score: \", accuracy_score(label_test, result)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Learning on text #####\n",
    "text_train, text_test, label_train, label_test = train_test_split(textVectorArray, labels, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = MultinomialNB()\n",
    "model2.fit(text_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model2.predict(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: \", accuracy_score(label_test, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Splitting before vectorization ###\n",
    "text_train, text_test, label_train, label_test = train_test_split(TextString, labels, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textVector = TfidfVectorizer()\n",
    "textVectorArray = textVector.fit_transform(text_train).toarray()\n",
    "textVectorArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(textVectorArray, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testVectorArray = textVector.transform(text_test).toarray()\n",
    "testVectorArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8729281767955801\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(testVectorArray)\n",
    "print(\"Accuracy: \" , accuracy_score(label_test, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# LEARNING ON BOTH FEATURES ############\n",
    "VectorArray = np.concatenate((titleVectorArray, textVectorArray), axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "VectorArray_train, VectorArray_test, label_train, label_test = train_test_split(VectorArray, labels, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14, 0.14100000000000001, 0.14200000000000002, 0.14300000000000002, 0.14400000000000002, 0.145, 0.146, 0.147, 0.148, 0.149, 0.15, 0.151, 0.152, 0.153, 0.154, 0.155, 0.156, 0.157, 0.158, 0.159, 0.16, 0.161, 0.162, 0.163, 0.164, 0.165, 0.166, 0.167, 0.168, 0.169, 0.17, 0.171, 0.17200000000000001, 0.17300000000000001, 0.17400000000000002, 0.17500000000000002, 0.176, 0.177, 0.178, 0.179, 0.18]\n"
     ]
    }
   ],
   "source": [
    "l1=list(range(140,181))\n",
    "for i in range(len(l1)):\n",
    "    l1[i]=l1[i]*0.001\n",
    "print(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': [0.14, 0.14100000000000001, 0.14200000000000002, 0.14300000000000002, 0.14400000000000002, 0.145, 0.146, 0.147, 0.148, 0.149, 0.15, 0.151, 0.152, 0.153, 0.154, 0.155, 0.156, 0.157, 0.158, 0.159, 0.16, 0.161, 0.162, 0.163, 0.164, 0.165, 0.166, 0.167, 0.168, 0.169, 0.17, 0.171, 0.17200000000000001, 0.17300000000000001, 0.17400000000000002, 0.17500000000000002, 0.176, 0.177, 0.178, 0.179, 0.18]}\n"
     ]
    }
   ],
   "source": [
    "##GridSearch\n",
    "param_grid=dict(alpha=l1)\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(721, 19735)\n",
      "(721,)\n"
     ]
    }
   ],
   "source": [
    "print(VectorArray_train)\n",
    "print(VectorArray_train.shape)\n",
    "print(label_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'alpha': [0.14, 0.14100000000000001, 0.14200000000000002, 0.14300000000000002, 0.14400000000000002, 0.145, 0.146, 0.147, 0.148, 0.149, 0.15, 0.151, 0.152, 0.153, 0.154, 0.155, 0.156, 0.157, 0.158, 0.159, 0.16, 0.161, 0.162, 0.163, 0.164, 0.165, 0.166, 0.167, 0.168, 0.169, 0.17, 0.171, 0.17200000000000001, 0.17300000000000001, 0.17400000000000002, 0.17500000000000002, 0.176, 0.177, 0.178, 0.179, 0.18]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb=MultinomialNB()\n",
    "grid = GridSearchCV(nb, param_grid, cv=10,return_train_score=False)\n",
    "grid.fit(VectorArray_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.18289816, 0.1776248 , 0.17778761, 0.17751832, 0.17697539,\n",
       "        0.18094132, 0.1788348 , 0.17599354, 0.17612436, 0.1773385 ,\n",
       "        0.18137074, 0.17811606, 0.17780075, 0.17919927, 0.1692522 ,\n",
       "        0.19034219, 0.17956502, 0.18122633, 0.1725791 , 0.17358935,\n",
       "        0.17171221, 0.17709191, 0.16923482, 0.17282295, 0.17331507,\n",
       "        0.18079774, 0.17471702, 0.17004294, 0.18157594, 0.18147161,\n",
       "        0.18010457, 0.17785928, 0.17213347, 0.17678635, 0.18269358,\n",
       "        0.17580664, 0.17607808, 0.17780609, 0.18186433, 0.17772245,\n",
       "        0.1743567 ]),\n",
       " 'std_fit_time': array([0.01904377, 0.00866213, 0.01029474, 0.01252896, 0.00634623,\n",
       "        0.00646704, 0.00993986, 0.00558153, 0.00604343, 0.01251541,\n",
       "        0.01357419, 0.0134805 , 0.00671446, 0.01179092, 0.01138041,\n",
       "        0.02253362, 0.01329728, 0.01606442, 0.017877  , 0.00359371,\n",
       "        0.00624445, 0.00758744, 0.01024447, 0.0084632 , 0.00474678,\n",
       "        0.01053415, 0.01455977, 0.01426664, 0.00559577, 0.01289281,\n",
       "        0.00593436, 0.01009371, 0.00632104, 0.00781563, 0.0166019 ,\n",
       "        0.01540647, 0.00653433, 0.00819595, 0.00947738, 0.00445844,\n",
       "        0.00356163]),\n",
       " 'mean_score_time': array([0.00730295, 0.00447121, 0.00674775, 0.00599477, 0.00435412,\n",
       "        0.0032614 , 0.00595138, 0.00704782, 0.00395973, 0.00480754,\n",
       "        0.00384843, 0.00442195, 0.00395665, 0.00256488, 0.00772276,\n",
       "        0.00639896, 0.00448508, 0.00268722, 0.00687869, 0.00675869,\n",
       "        0.00709205, 0.00199549, 0.00764375, 0.00572481, 0.005619  ,\n",
       "        0.00469291, 0.00510211, 0.00629325, 0.00263159, 0.00692656,\n",
       "        0.00396006, 0.00959048, 0.00522568, 0.00511382, 0.00858414,\n",
       "        0.00327184, 0.00771668, 0.00398958, 0.00125916, 0.00370719,\n",
       "        0.00279496]),\n",
       " 'std_score_time': array([0.00563025, 0.00445238, 0.00478716, 0.0068111 , 0.00444297,\n",
       "        0.00164163, 0.00558553, 0.00715129, 0.00428002, 0.00572743,\n",
       "        0.00308428, 0.00591167, 0.00427967, 0.00464113, 0.00697794,\n",
       "        0.00583261, 0.00409245, 0.00496342, 0.00523594, 0.00393489,\n",
       "        0.00572923, 0.00199549, 0.0057692 , 0.00553919, 0.00548535,\n",
       "        0.00597662, 0.00419551, 0.00615896, 0.00270377, 0.00485913,\n",
       "        0.00496941, 0.00675612, 0.00580455, 0.00483419, 0.00697239,\n",
       "        0.00460014, 0.00426278, 0.00252353, 0.00195058, 0.00240292,\n",
       "        0.00182974]),\n",
       " 'param_alpha': masked_array(data=[0.14, 0.14100000000000001, 0.14200000000000002,\n",
       "                    0.14300000000000002, 0.14400000000000002, 0.145, 0.146,\n",
       "                    0.147, 0.148, 0.149, 0.15, 0.151, 0.152, 0.153, 0.154,\n",
       "                    0.155, 0.156, 0.157, 0.158, 0.159, 0.16, 0.161, 0.162,\n",
       "                    0.163, 0.164, 0.165, 0.166, 0.167, 0.168, 0.169, 0.17,\n",
       "                    0.171, 0.17200000000000001, 0.17300000000000001,\n",
       "                    0.17400000000000002, 0.17500000000000002, 0.176, 0.177,\n",
       "                    0.178, 0.179, 0.18],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'alpha': 0.14},\n",
       "  {'alpha': 0.14100000000000001},\n",
       "  {'alpha': 0.14200000000000002},\n",
       "  {'alpha': 0.14300000000000002},\n",
       "  {'alpha': 0.14400000000000002},\n",
       "  {'alpha': 0.145},\n",
       "  {'alpha': 0.146},\n",
       "  {'alpha': 0.147},\n",
       "  {'alpha': 0.148},\n",
       "  {'alpha': 0.149},\n",
       "  {'alpha': 0.15},\n",
       "  {'alpha': 0.151},\n",
       "  {'alpha': 0.152},\n",
       "  {'alpha': 0.153},\n",
       "  {'alpha': 0.154},\n",
       "  {'alpha': 0.155},\n",
       "  {'alpha': 0.156},\n",
       "  {'alpha': 0.157},\n",
       "  {'alpha': 0.158},\n",
       "  {'alpha': 0.159},\n",
       "  {'alpha': 0.16},\n",
       "  {'alpha': 0.161},\n",
       "  {'alpha': 0.162},\n",
       "  {'alpha': 0.163},\n",
       "  {'alpha': 0.164},\n",
       "  {'alpha': 0.165},\n",
       "  {'alpha': 0.166},\n",
       "  {'alpha': 0.167},\n",
       "  {'alpha': 0.168},\n",
       "  {'alpha': 0.169},\n",
       "  {'alpha': 0.17},\n",
       "  {'alpha': 0.171},\n",
       "  {'alpha': 0.17200000000000001},\n",
       "  {'alpha': 0.17300000000000001},\n",
       "  {'alpha': 0.17400000000000002},\n",
       "  {'alpha': 0.17500000000000002},\n",
       "  {'alpha': 0.176},\n",
       "  {'alpha': 0.177},\n",
       "  {'alpha': 0.178},\n",
       "  {'alpha': 0.179},\n",
       "  {'alpha': 0.18}],\n",
       " 'split0_test_score': array([0.94520548, 0.94520548, 0.94520548, 0.94520548, 0.94520548,\n",
       "        0.94520548, 0.94520548, 0.94520548, 0.94520548, 0.94520548,\n",
       "        0.94520548, 0.94520548, 0.94520548, 0.94520548, 0.94520548,\n",
       "        0.94520548, 0.94520548, 0.94520548, 0.94520548, 0.94520548,\n",
       "        0.94520548, 0.94520548, 0.94520548, 0.94520548, 0.94520548,\n",
       "        0.94520548, 0.94520548, 0.94520548, 0.94520548, 0.94520548,\n",
       "        0.94520548, 0.94520548, 0.94520548, 0.94520548, 0.94520548,\n",
       "        0.94520548, 0.94520548, 0.94520548, 0.94520548, 0.94520548,\n",
       "        0.94520548]),\n",
       " 'split1_test_score': array([0.8630137 , 0.8630137 , 0.8630137 , 0.8630137 , 0.8630137 ,\n",
       "        0.8630137 , 0.8630137 , 0.84931507, 0.84931507, 0.84931507,\n",
       "        0.84931507, 0.84931507, 0.84931507, 0.84931507, 0.84931507,\n",
       "        0.84931507, 0.84931507, 0.84931507, 0.84931507, 0.84931507,\n",
       "        0.84931507, 0.84931507, 0.84931507, 0.84931507, 0.84931507,\n",
       "        0.84931507, 0.84931507, 0.84931507, 0.84931507, 0.84931507,\n",
       "        0.84931507, 0.84931507, 0.84931507, 0.84931507, 0.84931507,\n",
       "        0.84931507, 0.84931507, 0.84931507, 0.84931507, 0.84931507,\n",
       "        0.84931507]),\n",
       " 'split2_test_score': array([0.89041096, 0.89041096, 0.89041096, 0.89041096, 0.89041096,\n",
       "        0.89041096, 0.89041096, 0.89041096, 0.89041096, 0.89041096,\n",
       "        0.89041096, 0.89041096, 0.89041096, 0.89041096, 0.89041096,\n",
       "        0.89041096, 0.89041096, 0.89041096, 0.89041096, 0.89041096,\n",
       "        0.89041096, 0.89041096, 0.89041096, 0.89041096, 0.89041096,\n",
       "        0.89041096, 0.89041096, 0.89041096, 0.89041096, 0.89041096,\n",
       "        0.89041096, 0.89041096, 0.89041096, 0.89041096, 0.89041096,\n",
       "        0.89041096, 0.89041096, 0.89041096, 0.89041096, 0.89041096,\n",
       "        0.89041096]),\n",
       " 'split3_test_score': array([0.91780822, 0.91780822, 0.91780822, 0.91780822, 0.91780822,\n",
       "        0.91780822, 0.91780822, 0.91780822, 0.91780822, 0.91780822,\n",
       "        0.91780822, 0.91780822, 0.91780822, 0.91780822, 0.91780822,\n",
       "        0.91780822, 0.91780822, 0.91780822, 0.91780822, 0.91780822,\n",
       "        0.91780822, 0.91780822, 0.91780822, 0.91780822, 0.91780822,\n",
       "        0.91780822, 0.91780822, 0.91780822, 0.91780822, 0.91780822,\n",
       "        0.91780822, 0.91780822, 0.91780822, 0.91780822, 0.91780822,\n",
       "        0.91780822, 0.91780822, 0.91780822, 0.91780822, 0.91780822,\n",
       "        0.91780822]),\n",
       " 'split4_test_score': array([0.93055556, 0.93055556, 0.93055556, 0.93055556, 0.93055556,\n",
       "        0.93055556, 0.93055556, 0.93055556, 0.93055556, 0.93055556,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444]),\n",
       " 'split5_test_score': array([0.88888889, 0.88888889, 0.88888889, 0.88888889, 0.88888889,\n",
       "        0.88888889, 0.88888889, 0.88888889, 0.88888889, 0.88888889,\n",
       "        0.88888889, 0.88888889, 0.88888889, 0.88888889, 0.88888889,\n",
       "        0.88888889, 0.88888889, 0.88888889, 0.88888889, 0.88888889,\n",
       "        0.88888889, 0.90277778, 0.90277778, 0.90277778, 0.90277778,\n",
       "        0.90277778, 0.90277778, 0.90277778, 0.90277778, 0.90277778,\n",
       "        0.90277778, 0.90277778, 0.90277778, 0.90277778, 0.90277778,\n",
       "        0.90277778, 0.90277778, 0.90277778, 0.90277778, 0.90277778,\n",
       "        0.90277778]),\n",
       " 'split6_test_score': array([0.93055556, 0.93055556, 0.93055556, 0.93055556, 0.93055556,\n",
       "        0.93055556, 0.93055556, 0.93055556, 0.93055556, 0.93055556,\n",
       "        0.93055556, 0.93055556, 0.93055556, 0.93055556, 0.93055556,\n",
       "        0.93055556, 0.93055556, 0.93055556, 0.93055556, 0.93055556,\n",
       "        0.93055556, 0.93055556, 0.93055556, 0.93055556, 0.93055556,\n",
       "        0.93055556, 0.93055556, 0.93055556, 0.93055556, 0.93055556,\n",
       "        0.93055556, 0.93055556, 0.93055556, 0.93055556, 0.93055556,\n",
       "        0.93055556, 0.93055556, 0.93055556, 0.93055556, 0.93055556,\n",
       "        0.93055556]),\n",
       " 'split7_test_score': array([0.87323944, 0.87323944, 0.87323944, 0.87323944, 0.87323944,\n",
       "        0.87323944, 0.87323944, 0.87323944, 0.87323944, 0.87323944,\n",
       "        0.87323944, 0.87323944, 0.87323944, 0.87323944, 0.87323944,\n",
       "        0.87323944, 0.87323944, 0.87323944, 0.87323944, 0.87323944,\n",
       "        0.87323944, 0.87323944, 0.87323944, 0.87323944, 0.87323944,\n",
       "        0.87323944, 0.87323944, 0.87323944, 0.87323944, 0.87323944,\n",
       "        0.87323944, 0.87323944, 0.87323944, 0.87323944, 0.87323944,\n",
       "        0.87323944, 0.87323944, 0.87323944, 0.87323944, 0.87323944,\n",
       "        0.87323944]),\n",
       " 'split8_test_score': array([0.87323944, 0.87323944, 0.87323944, 0.85915493, 0.85915493,\n",
       "        0.85915493, 0.85915493, 0.85915493, 0.85915493, 0.85915493,\n",
       "        0.85915493, 0.85915493, 0.85915493, 0.85915493, 0.85915493,\n",
       "        0.85915493, 0.85915493, 0.85915493, 0.85915493, 0.85915493,\n",
       "        0.85915493, 0.85915493, 0.85915493, 0.85915493, 0.84507042,\n",
       "        0.84507042, 0.84507042, 0.84507042, 0.84507042, 0.84507042,\n",
       "        0.85915493, 0.85915493, 0.85915493, 0.85915493, 0.85915493,\n",
       "        0.85915493, 0.85915493, 0.85915493, 0.85915493, 0.85915493,\n",
       "        0.85915493]),\n",
       " 'split9_test_score': array([0.85915493, 0.85915493, 0.85915493, 0.85915493, 0.85915493,\n",
       "        0.85915493, 0.85915493, 0.85915493, 0.85915493, 0.85915493,\n",
       "        0.85915493, 0.85915493, 0.85915493, 0.85915493, 0.85915493,\n",
       "        0.85915493, 0.85915493, 0.85915493, 0.85915493, 0.85915493,\n",
       "        0.85915493, 0.85915493, 0.85915493, 0.85915493, 0.85915493,\n",
       "        0.85915493, 0.85915493, 0.85915493, 0.85915493, 0.85915493,\n",
       "        0.85915493, 0.85915493, 0.85915493, 0.85915493, 0.85915493,\n",
       "        0.85915493, 0.85915493, 0.85915493, 0.85915493, 0.85915493,\n",
       "        0.85915493]),\n",
       " 'mean_test_score': array([0.89736477, 0.89736477, 0.89736477, 0.89597781, 0.89597781,\n",
       "        0.89597781, 0.89597781, 0.89459085, 0.89459085, 0.89459085,\n",
       "        0.89597781, 0.89597781, 0.89597781, 0.89597781, 0.89597781,\n",
       "        0.89597781, 0.89597781, 0.89597781, 0.89597781, 0.89597781,\n",
       "        0.89597781, 0.89736477, 0.89736477, 0.89736477, 0.89597781,\n",
       "        0.89597781, 0.89597781, 0.89597781, 0.89597781, 0.89597781,\n",
       "        0.89736477, 0.89736477, 0.89736477, 0.89736477, 0.89736477,\n",
       "        0.89736477, 0.89736477, 0.89736477, 0.89736477, 0.89736477,\n",
       "        0.89736477]),\n",
       " 'std_test_score': array([0.02973231, 0.02973231, 0.02973231, 0.03112142, 0.03112142,\n",
       "        0.03112142, 0.03112142, 0.03281858, 0.03281858, 0.03281858,\n",
       "        0.03455665, 0.03455665, 0.03455665, 0.03455665, 0.03455665,\n",
       "        0.03455665, 0.03455665, 0.03455665, 0.03455665, 0.03455665,\n",
       "        0.03455665, 0.034523  , 0.034523  , 0.034523  , 0.03626899,\n",
       "        0.03626899, 0.03626899, 0.03626899, 0.03626899, 0.03626899,\n",
       "        0.034523  , 0.034523  , 0.034523  , 0.034523  , 0.034523  ,\n",
       "        0.034523  , 0.034523  , 0.034523  , 0.034523  , 0.034523  ,\n",
       "        0.034523  ]),\n",
       " 'rank_test_score': array([ 1,  1,  1, 18, 18, 18, 18, 39, 39, 39, 18, 18, 18, 18, 18, 18, 18,\n",
       "        18, 18, 18, 18,  1,  1,  1, 18, 18, 18, 18, 18, 18,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1])}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.897364771151179"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.14}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.14, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelx = MultinomialNB(alpha=0.14)\n",
    "modelx.fit(VectorArray_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = modelx.predict(VectorArray_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9281767955801105\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", accuracy_score(label_test, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721 721\n"
     ]
    }
   ],
   "source": [
    "################### Learning on Just source ###########\n",
    "source_train, source_train, label_train, label_test = train_test_split(source, label, test_size=0.2, random_state=7)\n",
    "print(len(source_train), len(label_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'realnewsrightnow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-4f06b9623f32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodely\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodely\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodely\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tutorial\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m         \"\"\"\n\u001b[1;32m--> 609\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    610\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tutorial\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_class_log_prior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_prior\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tutorial\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    756\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tutorial\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tutorial\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tutorial\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    752\u001b[0m               dtype='datetime64[ns]')\n\u001b[0;32m    753\u001b[0m         \"\"\"\n\u001b[1;32m--> 754\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tutorial\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tutorial\\lib\\site-packages\\pandas\\core\\arrays\\numpy_.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[0m_HANDLED_TYPES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tutorial\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'realnewsrightnow'"
     ]
    }
   ],
   "source": [
    "modely = MultinomialNB()\n",
    "modely.fit(source_train, label_train)\n",
    "result = modely.predict(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 19735)\n",
      "(1, 19735)\n"
     ]
    }
   ],
   "source": [
    "def l2s(L):\n",
    "    return \" \".join(L)\n",
    "ti = \"\"\n",
    "s = l2s(clean(nltk.word_tokenize(ti)))\n",
    "tiVector = titleVector.transform([s]).toarray()\n",
    "new = \"Take a deep breath and hold your breath for more than 10 seconds. If you complete it successfully without coughing, without discomfort stiffness or tightness, etc., it proves there is no Fibrosis in the lungs, basically indicates no infection.In critical time, please self-check every morning in an environment with clean air\"\n",
    "newVector= textVector.transform([l2s(clean(nltk.word_tokenize(new)))]).toarray()\n",
    "\n",
    "vec = np.concatenate((tiVector,newVector), axis=1)\n",
    "print(vec.shape)\n",
    "print(vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True]\n"
     ]
    }
   ],
   "source": [
    "print(modelx.predict(vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(902, 19735)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################################################V\n",
    "\n",
    "VectorArray = np.concatenate((titleVectorArray, textVectorArray), axis=1)\n",
    "VectorArray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "VA_train, VA_test, label_train, label_test = train_test_split(VectorArray, labels, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721 721\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      need james bond recogn fact modern american pr...\n",
       "1      cnn japanese prime minister shinzo abe insist ...\n",
       "2      london cnn outbreak novel coronavirus caus pol...\n",
       "3      chat us facebook messenger find happen world u...\n",
       "4      london cnn business company spent year sinc gl...\n",
       "                             ...                        \n",
       "897    hanoi detail emerg suggest president trump wal...\n",
       "898    viral drinking game involves consum shot everi...\n",
       "899    london trump tweet excitement becom first amer...\n",
       "900    accumul many assum damn evidence ever sit pres...\n",
       "901    fussa president united state begun tour asia m...\n",
       "Name: TextString, Length: 902, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TitleString\n",
    "TextString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_train, title_test, text_train, text_test, label_train, label_test = train_test_split(TitleString, TextString, labels, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(721, 2651)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titleVector = TfidfVectorizer()\n",
    "titleVectorArray = titleVector.fit_transform(title_train).toarray()\n",
    "titleVectorArray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(721, 15055)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textVector = TfidfVectorizer()\n",
    "textVectorArray = textVector.fit_transform(text_train).toarray()\n",
    "textVectorArray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(721, 17706)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = np.concatenate((titleVectorArray, textVectorArray), axis=1)\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': [0.01, 0.02, 0.03, 0.001, 0.002, 0.003, 0.0001, 0.0002, 0.0003]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ansar\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'alpha': [0.01, 0.02, 0.03, 0.001, 0.002, 0.003, 0.0001, 0.0002, 0.0003]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##GridSearch\n",
    "param_grid=dict(alpha=[0.01,0.02,0.03,0.001,0.002,0.003,0.0001,0.0002,0.0003])\n",
    "print(param_grid)\n",
    "nb=MultinomialNB()\n",
    "grid = GridSearchCV(nb, param_grid, cv=10,return_train_score=False)\n",
    "grid.fit(vector,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.08938956, 0.09128578, 0.08325143, 0.08297076, 0.08333082,\n",
       "        0.08491924, 0.08272619, 0.08228238, 0.08427498]),\n",
       " 'std_fit_time': array([0.00655918, 0.00707767, 0.00414112, 0.0033143 , 0.00252898,\n",
       "        0.00594827, 0.00318342, 0.00135652, 0.00149597]),\n",
       " 'mean_score_time': array([0.00361154, 0.00221179, 0.0023082 , 0.00281231, 0.00249393,\n",
       "        0.0025104 , 0.00231433, 0.00269392, 0.0025934 ]),\n",
       " 'std_score_time': array([0.00292444, 0.00339817, 0.00288371, 0.00283418, 0.00091981,\n",
       "        0.00345733, 0.00354823, 0.0006387 , 0.00048862]),\n",
       " 'param_alpha': masked_array(data=[0.01, 0.02, 0.03, 0.001, 0.002, 0.003, 0.0001, 0.0002,\n",
       "                    0.0003],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'alpha': 0.01},\n",
       "  {'alpha': 0.02},\n",
       "  {'alpha': 0.03},\n",
       "  {'alpha': 0.001},\n",
       "  {'alpha': 0.002},\n",
       "  {'alpha': 0.003},\n",
       "  {'alpha': 0.0001},\n",
       "  {'alpha': 0.0002},\n",
       "  {'alpha': 0.0003}],\n",
       " 'split0_test_score': array([0.91780822, 0.93150685, 0.93150685, 0.94520548, 0.94520548,\n",
       "        0.91780822, 0.91780822, 0.93150685, 0.93150685]),\n",
       " 'split1_test_score': array([0.89041096, 0.87671233, 0.87671233, 0.89041096, 0.90410959,\n",
       "        0.90410959, 0.89041096, 0.89041096, 0.89041096]),\n",
       " 'split2_test_score': array([0.89041096, 0.8630137 , 0.8630137 , 0.8630137 , 0.89041096,\n",
       "        0.89041096, 0.83561644, 0.84931507, 0.84931507]),\n",
       " 'split3_test_score': array([0.89041096, 0.87671233, 0.87671233, 0.91780822, 0.90410959,\n",
       "        0.90410959, 0.91780822, 0.91780822, 0.91780822]),\n",
       " 'split4_test_score': array([0.91666667, 0.93055556, 0.94444444, 0.88888889, 0.90277778,\n",
       "        0.90277778, 0.88888889, 0.88888889, 0.88888889]),\n",
       " 'split5_test_score': array([0.86111111, 0.86111111, 0.875     , 0.88888889, 0.88888889,\n",
       "        0.88888889, 0.88888889, 0.88888889, 0.88888889]),\n",
       " 'split6_test_score': array([0.88888889, 0.90277778, 0.90277778, 0.86111111, 0.88888889,\n",
       "        0.88888889, 0.84722222, 0.84722222, 0.84722222]),\n",
       " 'split7_test_score': array([0.92957746, 0.91549296, 0.91549296, 0.87323944, 0.90140845,\n",
       "        0.90140845, 0.85915493, 0.85915493, 0.87323944]),\n",
       " 'split8_test_score': array([0.83098592, 0.84507042, 0.85915493, 0.85915493, 0.84507042,\n",
       "        0.83098592, 0.88732394, 0.87323944, 0.87323944]),\n",
       " 'split9_test_score': array([0.84507042, 0.85915493, 0.84507042, 0.83098592, 0.83098592,\n",
       "        0.83098592, 0.84507042, 0.84507042, 0.84507042]),\n",
       " 'mean_test_score': array([0.88626907, 0.88626907, 0.889043  , 0.88210818, 0.89042996,\n",
       "        0.88626907, 0.8779473 , 0.87933426, 0.88072122]),\n",
       " 'std_test_score': array([0.03024716, 0.02983904, 0.03121316, 0.03076084, 0.03032856,\n",
       "        0.02863527, 0.02805276, 0.02845533, 0.02777303]),\n",
       " 'rank_test_score': array([3, 3, 2, 6, 1, 3, 9, 8, 7])}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.8904299583911235\n",
      "best parameter: {'alpha': 0.002}\n"
     ]
    }
   ],
   "source": [
    "print(\"best score:\",grid.best_score_)\n",
    "print(\"best parameter:\",grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.002, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB(alpha=0.002)\n",
    "model.fit(vector, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181, 2651) (181, 15055)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(181, 17706)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titleTestVector = titleVector.transform(title_test).toarray()\n",
    "textTestVector = textVector.transform(text_test).toarray()\n",
    "print(titleTestVector.shape, textTestVector.shape)\n",
    "VectorTest = np.concatenate((titleTestVector, textTestVector), axis=1)\n",
    "VectorTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accu:  0.9171270718232044\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(VectorTest)\n",
    "print(\"Accu: \", accuracy_score(label_test, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickles/model\", \"wb\") as pick:\n",
    "    pickle.dump(model, pick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickles/titleVector\", \"wb\") as pick:\n",
    "    pickle.dump(titleVector, pick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickles/textVector\", \"wb\") as pick:\n",
    "    pickle.dump(textVector, pick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
